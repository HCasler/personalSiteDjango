<div id="videoDemo" class="pageContent">
    {% load static %}
    <div class="contentHeadline"><h1>Video Streaming Demo</h1></div>
    <div class="aboutMeContent">
        <p>Click play on the video below</p>
        <h3 id="demoVideoTitle"></h3>
        <p id="videoCredit"></p>
    </div>
         <video id="videoDemoPlayer" controls>
            <!--<source src="video/1/manifest.m3u8"> type="application/vnd.apple.mpegurl">-->
            Your browser does not support the video tag.
        </video> 
    

    <!-- Intro -->
    <div class="contentSection">
        <h3>This video was streamed using the HLS (HTTP Live Streaming) protocol</h3>
        <p>HLS is a common and widely-supported protocol for streaming video, both live and on demand. It allows for relatively low-latency, smooth streaming, with bit rate adaptation -- meaning, if you start watching a stream and then your internet connection becomes slower, the stream will switch to a lower bit rate that your connection can handle. Here, I'll talk a bit about how HLS works, and how I implemented it for this demo app.
        </p>
        <p>As always, if you are looking for someone to implement video streaming for your organization, feel free to <a href="#" onclick="displayPageContent('{% url "contact" %}', 'contact')">contact me.</a>
        </p>
    </div>

    <!-- Contents -->
    <div class="contentSection">
        <a href=#AboutHLS><p>About HLS</p></a>
        <a href=#ExternalImplementation><p>My implementation: what you can see</p></a>
        <a href=#InternalImplementation><p>My implementation: under the hood</p></a>
        <a href=#Simplifications><p>Simplifications just for this demo</p></a>
    </div>

    <!-- intro to HLS -->
    <div class = "contentSection" id="AboutHLS">
        <h3>About HLS</h3>
        <p>
            HLS was developed by Apple and first released in 2009. <a href=https://developer.apple.com/documentation/http-live-streaming/links-to-additional-specifications-and-videos  target="_blank" rel="noopener noreferrer">More information, including the full spec, can be found here.</a> It works by breaking up the video into small segments, which the player downloads one at a time. After each download, the player can choose whether to download the next segment using the same bit rate, or a different one, depending on things like how fast the previous download completed.
        </p>
        <p>
            There are three mains steps to playing an HLS stream. The first is to download the <b>master playlist,</b> which I have called "manifest.m3u8" in this demo. The master playlist contains links to <b>media playlists</b>, each of which represents a single video, audio, or subtitle stream. It also tells the player how these different streams are encoded, the required bandwith for each stream, and the screen resolution (for video streams). 
        </p>
        <p>
            The next step is to download the media playlists, which I have called "playlist.m3u8", associated with the streams the player wants to play. In this demo, I have provided only one audio stream and several options for video streams. Those playlists contain the names of <b>media segments,</b> files containing short sections of video or audio. The player downloads the first file in each list, starts playing it, and then keeps downloading more as the video continues. Ideally, by the time the player has finished playing one media segment, the next one has already been downloaded.
        </p>
    </div>

    <!-- externally visible parts of demo -->
    <div class = "contentSection" id="ExternalImplementation">
        <h3>My implementation: what you can see</h3>
        <p>
            If you open up the developer tools for this page and go to the network tab, you can find the request for manifest.m3u8 there. As of when I wrote this, the master playlist looks like: <pre style="overflow:auto;">
                <code>
#EXTM3U
#EXT-X-VERSION:6
#EXT-X-MEDIA:URI="subtitles/playlist.m3u8",TYPE=SUBTITLES,GROUP-ID="subtitles",LANGUAGE="en",NAME="English",DEFAULT=NO,AUTOSELECT=YES
#EXT-X-MEDIA:URI="audio/playlist.m3u8",TYPE=AUDIO,GROUP-ID="audio",LANGUAGE="en",NAME="English",DEFAULT=YES,AUTOSELECT=YES,CHANNELS="2"
#EXT-X-STREAM-INF:BANDWIDTH=110349081,RESOLUTION=3840x2160,CODECS="avc1.640034,mp4a.40.2,wvtt",AUDIO="audio",SUBTITLES="subtitles"
110349081/playlist.m3u8
#EXT-X-STREAM-INF:BANDWIDTH=82849081,RESOLUTION=1920x1080,CODECS="avc1.640032,mp4a.40.2,wvtt",AUDIO="audio",SUBTITLES="subtitles"
82849081/playlist.m3u8
#EXT-X-STREAM-INF:BANDWIDTH=11349081,RESOLUTION=1920x1080,CODECS="avc1.640032,mp4a.40.2,wvtt",AUDIO="audio",SUBTITLES="subtitles"
11349081/playlist.m3u8
#EXT-X-STREAM-INF:BANDWIDTH=1449081,RESOLUTION=1280x720,CODECS="avc1.640020,mp4a.40.2,wvtt",AUDIO="audio",SUBTITLES="subtitles"
1449081/playlist.m3u8
                </code>
            </pre>
            The first two lines tell you what kind of file this is, and the protocol version. The second two tell the player where to find the playlists for the subtitle and audio streams. Note that these are referred to as "MEDIA," while video streams are referred to as "STREAM." Remaining lines give links to the playlists for the video streams. These include information about the bandwidth (the bit rate the player needs to support), the spatial resolution, and the encodings. Note how the "CODECS" attribute contains the video <i>and audio and subtitle</i> codecs &mdash; "avc.6400NN" is video, "mp4a.40.2" is audio, and "wvtt" is subtitle.
        </p>

        <p>Next, if you find one of the requests for a media playlist, you'll find it looks something like this: <pre>
            <code>
#EXTM3U
#EXT-X-VERSION:6
#EXT-X-TARGETDURATION:10
#EXT-X-MEDIA-SEQUENCE:0
#EXT-X-PLAYLIST-TYPE:VOD
#EXT-X-INDEPENDENT-SEGMENTS
#EXTINF:10.013333,
seg_00.ts
#EXTINF:10.013333,
seg_01.ts
... more ...
#EXTINF:1.234978,
seg_20.ts
#EXT-X-ENDLIST
            </code>
        </pre>
        The top section tells you that the segments should all be about 10 seconds long, and that each segment can be decoded and played on its own without requiring any information in other segments. The playlist type "VOD" stands for "video on demand"; that is, this is a complete video being played, not a livestream being transmitted as it is being created. After that, it lists each segment by first giving its duration, and then giving the name of the file containing the segment itself. One important note is that the actual urls the player uses prepend the segment file name with the path used to get the playlist. That is, if this playlist is the result of requesting <code>1449081/playlist.m3u8</code>, then the player will request <code>1449081/seg_00.ts</code> to get the first segment.
        </p>

        <p>Finally, the player requests the segments themselves. There are two main file formats used for HLS media segments (excluding subtitles): MPEG2-TS and fragmented MP4. I went with MPEG2-TS here. The main difference between them is where the metadata (used for decoding, timing, etc) is kept. In TS files, each file contains all its own metadata. This means that any arbitrary TS file taken from any playlist can be played on its own. Fragmented MP4 files, on the other hand, need what is called a Media Initialization Section, which lists the tracks and encoding, among other things. If you see something like <code>#EXT-X-MAP:URI="init.mp4"</code> in a playlist, the segments are probably fragmented MP4.</p>
    </div>

    <div class = "contentSection" id="InternalImplementation">
        <h3>My implementation: under the hood</h3>
        <p>
        The basic server-side procedure goes as follows: the video API receives a request for either a playlist or a media segment. It then reaches out to a database I set up for this purpose, which contains data regarding the main video, which playlists are associated with it, and which segments are associated with each playlist. For each playlist and media segment, the database also lists a location in the object store, where the file might be found. Once the API has retrieved this information, it collects the file from the object store and returns it to the requestor. For those who are interested, the video API is written in Python using the Django framework, the database is MySQL, and the object store is Azure Blob Storage.
        </p>
        <p>
        Some people might wonder why I did it this way, rather than simply giving the player the files' locations in the object store. The first reason is that this frees up the object store to use whatever file naming scheme makes the most sense, without having to be aware of how the files will be requested by the player. The second is that this keeps access to the object store under tight control: the only thing external users can do is request certain files for reading, and they can only request those files that I've chosen to make accessible via the video API.
        </p>
        <p>
            I pre-made all the segments and playlists using <a href=https://ffmpeg.org/ target="_blank" rel="noopener noreferrer">FFmpeg.</a> In certain circumstances, it may be better to only start with full video files, and make the segments "on the fly." I have done this in the past; it requires an understanding of how the MP4 and MP2TS file formats work. It also is not the same as encoding on the fly, which would take much longer. For this demo app though, there was no reason to do this.
        </p>
    </div>

    <div class = "contentSection" id="Simplifications">
        <h3>Simplifications just for this demo</h3>
        <p>
        HLS allows for segments and playlists to be encrypted, for instance via AES-128. I have chosen not to do this, in the interests of allowing people to investigate the demo themselves via their browser's developer tools.
        </p>
        <p>
        HLS also allows for special Iframe-only streams &mdash; these are streams containing only Iframes (that is, full-image frames with no dependence on previous frames), at a rate of about one per second. These are used for scrubbing; however, they are not supported by the Javascript library I am using for the player here, so I did not include them.
        </p>
        <p>
        For a video streaming app expecting broad use, I would also include a session API. This would use a header or other part of the request to tie each request for a playlist or segment to a particular streaming session. This would let the app set limits on which users can see which videos, for example.
        </p>
    </div>
</div>